{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "742f2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In the result file the title of the 'EVAoutput' section\n",
    "# is either as 'EVAoutput' or 'EVAOutput' so the script needs\n",
    "# to be changed based on the heading \n",
    "# (Usually if the first letter of the timeseries name is Captital, \n",
    "# the heading is 'EVAOutput' and vice-versa)\n",
    "\n",
    "\n",
    "import mikeio\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Setting the excel output file path and name\n",
    "output_file_name = 'Storm Surge Statistical Analysis'\n",
    "output_directory = r'G:\\MJI\\SKZ\\Script\\Strom Surge stastical Analysis_Trial\\Eva'\n",
    "\n",
    "# Creating the output file in the folder path\n",
    "output_file_path =os.path.join(output_directory, '{}.xlsx'.format(output_file_name))\n",
    "writer = pd.ExcelWriter(output_file_path, engine='openpyxl')\n",
    "\n",
    "# Iterating through all the eva result file in the folder\n",
    "# to extract the required eva analysis result\n",
    "for file_name in glob.glob(r\"G:\\MJI\\SKZ\\Script\\Strom Surge stastical Analysis_Trial\\Result\\*.res\"):\n",
    "    \n",
    "    # Splitting the path list to create a file path list\n",
    "    file_path_list = file_name.split(os.sep)\n",
    "    \n",
    "    # Reading the mike eva analysis result pfs file\n",
    "    pfs = mikeio.read_pfs(file_name)\n",
    "\n",
    "    # Creating the list of probability distribution method used for analysis\n",
    "    method_list = list(pfs.EVAOutput.DistributionAnalysis.keys())[6:]\n",
    "\n",
    "    # Defining a blank dataframe to store the analysis result information\n",
    "    analysis_df = pd.DataFrame()\n",
    "\n",
    "    # Creating a list from the return period used for analysis\n",
    "    return_period_list = pfs.EVAOutput.DistributionAnalysis.ReturnPeriods\n",
    "\n",
    "    # Iterating through each probability method to extract the required analysis information\n",
    "    for item_name in method_list:\n",
    "\n",
    "        # Defining a dataframe to store particular method analysis information\n",
    "        method_df = pd.DataFrame()\n",
    "\n",
    "        # Extracting the distribution method label/name used in the reult file\n",
    "        method_name = pfs.EVAOutput.DistributionAnalysis[item_name].ItemName\n",
    "\n",
    "        # Creating a list from the all the goodness parameter that is available in the mike eva analysis tool\n",
    "        goodness_fit_parameter_list = list(pfs.EVAOutput.DistributionAnalysis[item_name].GoodnessOfFitStatistics.keys())\n",
    "\n",
    "        # Extacting the estimated, average quantile distribution value\n",
    "        # and also the standard deviation value\n",
    "        estimated_quantile = pfs.EVAOutput.DistributionAnalysis[item_name].TyearEventTable.TyearEvent\n",
    "        average_quantile = pfs.EVAOutput.DistributionAnalysis[item_name].TyearEventTable.AvgTyearEvent\n",
    "        standard_deviation = pfs.EVAOutput.DistributionAnalysis[item_name].TyearEventTable.StdTyearEvent\n",
    "\n",
    "        # Creating individual dataframe using the average, estimate quantile data and standard deviation data\n",
    "        estimated_df = pd.DataFrame({'Item type': 'Estimated Quantile', 'Return Period (years)': return_period_list,\n",
    "                                    method_name : estimated_quantile})\n",
    "\n",
    "        average_df = pd.DataFrame({'Item type': 'Average Quantile', 'Return Period (years)': return_period_list,\n",
    "                                    method_name : average_quantile})\n",
    "\n",
    "        standard_deviation_df = pd.DataFrame({'Item type': 'Standard deviation', 'Return Period (years)': return_period_list,\n",
    "                                    method_name : standard_deviation})\n",
    "\n",
    "        # Defining a list to store the goodness test name\n",
    "        goodness_test_list = []\n",
    "\n",
    "        # Iterating through all the goodness parameter and\n",
    "        # Extracting only the goodness test name\n",
    "        for parameter in goodness_fit_parameter_list:\n",
    "\n",
    "            if parameter[-4:] == 'Test':\n",
    "                goodness_test_list.append(parameter)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        # Defining blank list to store the goodness test parameter \n",
    "        # and analysis goodness test value \n",
    "        goodness_parameter = []\n",
    "        goodness_statistics = []\n",
    "\n",
    "\n",
    "        # Iterating through the goodness fit test list and checking whether it is used or not\n",
    "        # if it retruns \"True\" then appending the test name and calculated value into the list\n",
    "        for test_type in goodness_test_list:\n",
    "\n",
    "            if pfs.EVAOutput.DistributionAnalysis[item_name].GoodnessOfFitStatistics[test_type] == True:\n",
    "\n",
    "                stat_item_name = '{}Statistic'.format(test_type[:-4])\n",
    "                test_type_statistic = pfs.EVAOutput.DistributionAnalysis[item_name].GoodnessOfFitStatistics[stat_item_name]\n",
    "\n",
    "                goodness_parameter.append(test_type)\n",
    "                goodness_statistics.append(test_type_statistic)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        # Creating dataframe using the of goodness fit test information\n",
    "        goodness_df = pd.DataFrame({'Item type': 'Goodness of fit', 'Return Period (years)': goodness_parameter,\n",
    "                                    method_name : goodness_statistics})\n",
    "\n",
    "        # Updating the estimated quantile, average quantile, standard deviation and goodness fit test\n",
    "        # Information into the distribution method dataframe\n",
    "        method_df = pd.concat([estimated_df, average_df, standard_deviation_df, goodness_df])\n",
    "\n",
    "\n",
    "        # Updating the distribution method information into the combined method dataframe\n",
    "        if analysis_df.empty:\n",
    "            analysis_df = pd.concat([analysis_df, method_df])\n",
    "\n",
    "        else:\n",
    "            analysis_df = pd.merge(analysis_df, method_df, on = ['Item type', 'Return Period (years)'])\n",
    "    \n",
    "    # Adding the analysis summary as a new workbook in the excel file\n",
    "    analysis_df.to_excel(writer, sheet_name= \"{}\".format(file_path_list[-1][:-4]), index=False)\n",
    "\n",
    "# Saving the excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9ff44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
