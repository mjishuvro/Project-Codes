{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53fea5a",
   "metadata": {},
   "source": [
    "# BWDB Tidal Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3768d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!ERROR!!!! SW180 (Narayanganj)\n",
      "!!!!ERROR!!!! SW3A (Brahmanbaria)\n"
     ]
    }
   ],
   "source": [
    "import mikeio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from calendar import monthrange\n",
    "\n",
    "\n",
    "# function for creating blank time series at \"specified interval\" \n",
    "# creating a dictinary with first_date & end_date of each month of each year \n",
    "def blank_ts_and_year_dict(dataframe):\n",
    "\n",
    "    df = dataframe\n",
    "\n",
    "    start_end_time_dict = {}\n",
    "\n",
    "    total_time_df = pd.DataFrame()\n",
    "\n",
    "    start_yr = df['Date'].dt.year.unique().min()\n",
    "    end_yr = df['Date'].dt.year.unique().max()\n",
    "\n",
    "\n",
    "    year_list = [y for y in range(start_yr, end_yr+1 , 1)]\n",
    "\n",
    "    for yr in year_list:\n",
    "\n",
    "        year_dict = {}\n",
    "\n",
    "        yr_df = df[df['Date'].dt.strftime('%Y') == str(yr)]\n",
    "\n",
    "        months_list = [m for m in range(1, 12+1 , 1)]\n",
    "\n",
    "\n",
    "        yearly_time_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        for month in months_list:\n",
    "\n",
    "            start_end_time_list = []\n",
    "\n",
    "            end_day = monthrange(yr, month)[1]\n",
    "\n",
    "            start_date = (datetime(year= yr, month= month, day=1, hour=0, minute=0, second =0)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            end_date = (datetime(year= yr, month= month, day= end_day, hour=23, minute=30, second =0)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            start_end_time_list.append(start_date)\n",
    "            start_end_time_list.append(end_date)\n",
    "\n",
    "            monthly_time_list = pd.date_range(start_date, end_date, freq=\"30min\")\n",
    "\n",
    "            monthly_time_df = pd.DataFrame({'Date':monthly_time_list})\n",
    "\n",
    "            yearly_time_df = pd.concat([yearly_time_df,monthly_time_df])\n",
    "\n",
    "            year_dict[str(month)] = start_end_time_list\n",
    "\n",
    "        total_time_df = pd.concat([total_time_df,yearly_time_df])\n",
    "\n",
    "        start_end_time_dict[str(yr)] = year_dict\n",
    "\n",
    "    return total_time_df, start_end_time_dict\n",
    "\n",
    "\n",
    "# Defining a function to extract daily maximum and minimum value and calculating their average\n",
    "def daily_avg_wl_df(timeseries_df, column_name):\n",
    "    \n",
    "    without_duplicate_df = timeseries_df\n",
    "\n",
    "    max_min_column = column_name\n",
    "\n",
    "    # Extracting daily max and min value from timeseries data\n",
    "    # Defining two dataframes to store daily maximum and minimum value\n",
    "    max_df = pd.DataFrame()\n",
    "    min_df = pd.DataFrame()\n",
    "\n",
    "    # looping through all the unique date in the timeseries dataframe to determine daily maximum and minimum value\n",
    "    for day in without_duplicate_df['Date'].dt.date.unique():\n",
    "\n",
    "        # Creating a dataframe by matching the date\n",
    "        day_df = without_duplicate_df[without_duplicate_df['Date'].dt.date == day]\n",
    "\n",
    "        # Finding daily maximum and minimum value for the required cloumn and also extracting associated other column data\n",
    "        max_row_df = day_df.nlargest(1, max_min_column)\n",
    "        min_row_df = day_df.nsmallest(1, max_min_column)\n",
    "\n",
    "        # Updating the maximum and minimum value in the max_df and min_df respectively\n",
    "        max_df = pd.concat([max_df, max_row_df])\n",
    "        min_df = pd.concat([min_df, min_row_df])\n",
    "\n",
    "    # Creating a dataframe by merging maximum and minimum dataframe\n",
    "    daily_max_min_df = pd.concat([max_df, min_df])\n",
    "\n",
    "    # Sorting the dataframe by \"Date\" [Oldest to Newest]\n",
    "    daily_max_min_df.sort_values(by='Date',ascending=True, inplace = False)\n",
    "\n",
    "    # Calculating daily average value from daily maximum and minimum value and reseting the index\n",
    "    davg_df = daily_max_min_df.groupby(by=daily_max_min_df['Date'].dt.date).mean()\n",
    "    davg_df.reset_index(inplace = True)\n",
    "    davg_df['Date'] = pd.to_datetime(davg_df['Date'], format=\"%Y-%m-%d\")\n",
    "    \n",
    "    return daily_max_min_df, davg_df\n",
    "\n",
    "\n",
    "# Function for calculating the average of each column the dataframe except the date column and then transposing it\n",
    "def df_column_avg(df):\n",
    "    \n",
    "    a_df = pd.DataFrame(df.loc[:, df.columns != \"Date\"].mean())\n",
    "    ret_df = a_df.transpose()\n",
    "    \n",
    "    return ret_df\n",
    "\n",
    "\n",
    "\n",
    "# Function for creating segment wise water level average \n",
    "def seg_wl_average(no_of_intervals, time_dic, timeseries_df):\n",
    "\n",
    "    N = no_of_intervals\n",
    "    start_end_time_dict = time_dic\n",
    "    m_df = timeseries_df\n",
    "    \n",
    "    wl_df = pd.DataFrame()\n",
    "    \n",
    "    for yr_key in start_end_time_dict:\n",
    "        for month_key in start_end_time_dict[yr_key]:\n",
    "            first_date = start_end_time_dict[yr_key][month_key][0]\n",
    "            last_date = start_end_time_dict[yr_key][month_key][1]\n",
    "\n",
    "            start_datetime = pd.to_datetime(first_date)\n",
    "            end_datetime = pd.to_datetime(last_date)\n",
    "\n",
    "\n",
    "            dtm_list = []\n",
    "\n",
    "            diff = end_datetime - start_datetime\n",
    "\n",
    "            increment = (diff.round('D') - timedelta(days = diff.round('D').days % N))/ N\n",
    "\n",
    "            for idx in range(1, N+1, 1):\n",
    "\n",
    "                if idx == 0:\n",
    "                    dtm_list.append((start_datetime + idx * increment).strftime(\"%Y/%m/%d\"))\n",
    "\n",
    "                elif 0 < idx < N:\n",
    "                    dtm_list.append((start_datetime + idx * increment - timedelta(days=1)).strftime(\"%Y/%m/%d\"))\n",
    "\n",
    "                else:\n",
    "                    dtm_list.append((end_datetime).strftime(\"%Y/%m/%d\"))\n",
    "                    \n",
    "\n",
    "            for i in range(0,len(dtm_list)):\n",
    "\n",
    "                if i == 0:\n",
    "                    mask = (m_df['Date'] >= start_datetime) & (m_df['Date'] <= dtm_list[i])\n",
    "                    v_df = m_df.loc[mask]\n",
    "\n",
    "\n",
    "                    fdt_df = pd.DataFrame({'Date/Time':[dtm_list[i]]})\n",
    "                    avg_df = df_column_avg(v_df)\n",
    "                    n_df = pd.concat([fdt_df,avg_df], axis=1, join=\"inner\")\n",
    "                    n_df['Remarks'] = i+1\n",
    "\n",
    "                    wl_df = pd.concat([wl_df, n_df])\n",
    "\n",
    "                elif 0 < i < len(dtm_list):\n",
    "                    mask = (m_df['Date'] > dtm_list[i-1]) & (m_df['Date'] <= dtm_list[i])\n",
    "                    v_df = m_df.loc[mask]\n",
    "\n",
    "                    fdt_df = pd.DataFrame({'Date/Time':[dtm_list[i]]})\n",
    "                    avg_df = df_column_avg(v_df)\n",
    "                    n_df = pd.concat([fdt_df,avg_df], axis=1, join=\"inner\")\n",
    "                    n_df['Remarks'] = i+1\n",
    "\n",
    "                    wl_df = pd.concat([wl_df, n_df])\n",
    "\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "    return wl_df\n",
    "\n",
    "for file in glob.glob(r'G:\\MJI\\BWDB_Tidal (104 nos.)\\Tidal (104 nos.)\\*.dfs0'):\n",
    "    \n",
    "    try:\n",
    "        path_list = file.split(os.sep)\n",
    "\n",
    "        # Reading dfs0 file\n",
    "        ds = mikeio.read(file)\n",
    "\n",
    "        # Converting dataset to dataframe\n",
    "        df = ds.to_dataframe()\n",
    "\n",
    "        # Creating the date/time column and renaming it\n",
    "        df.reset_index(inplace =True)\n",
    "        df.rename(columns = {'index':'Date'}, inplace = True)\n",
    "        df.sort_values(by='Date',ascending=True, inplace = True)\n",
    "\n",
    "        # Rounding datetime time to nearest 30 minutes\n",
    "        df['Date'] = df.loc[:,'Date'].dt.round(freq='30T')\n",
    "\n",
    "\n",
    "        # Creating a datetime timeseries at 30 minutes interval \n",
    "        total_time_df, start_end_time_dict = blank_ts_and_year_dict(df)\n",
    "        total_time_df.reset_index(inplace = True, drop=True)\n",
    "\n",
    "        # Droping the 'Duplicate rows' and keeping the first value from duplicate rows\n",
    "        without_duplicate_df = df.drop_duplicates(subset=['Date'], keep='first')\n",
    "\n",
    "\n",
    "        # Merging Blank timeseries dataframe and processed dataframe from input timeseries together\n",
    "        ts_df = total_time_df.merge(without_duplicate_df, how=\"outer\", on=\"Date\")\n",
    "        ts_df.sort_values(by='Date',ascending=True, inplace = True)\n",
    "        ts_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        # Extracting the daily maximum and minimum and calculating their average, then returning their average using defined function\n",
    "        daily_max_min_df, davg_df = daily_avg_wl_df(timeseries_df = without_duplicate_df, column_name = 'Modified_Cyclone')\n",
    "\n",
    "        # Defining a dataframe blank daily timeseries dataframe (frequency = 1 day)\n",
    "        daily_ts_df = pd.DataFrame({'Date':ts_df['Date'].dt.date.unique()})\n",
    "        daily_ts_df['Date'] = pd.to_datetime(daily_ts_df['Date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "        # Merging daily blank timeseries dataframe and processed (from input timeseries) daily average water level dataframe together\n",
    "        equi_davg_df = daily_ts_df.merge(davg_df, how=\"outer\", on=\"Date\")\n",
    "\n",
    "        # Total number time segment in a month (example: fortnightly-2, weekly-4 etc.) [User Input]\n",
    "        no_of_intervals = 2   ## Fortnightly\n",
    "\n",
    "        # Applying function to calculate fortnightly average water level\n",
    "        fawl_df = seg_wl_average(no_of_intervals = no_of_intervals, time_dic = start_end_time_dict , timeseries_df = equi_davg_df)\n",
    "\n",
    "\n",
    "        # Saving 30 minutes interval timeseries file\n",
    "        ts_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Output\\30min_TS\\{}_30min_TS.xlsx\".format(path_list[-1][:-5]), \n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "        # Saving daily maximum and minimum timeseries file\n",
    "        daily_max_min_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Output\\Daily_Max_Min\\{}_Daily_Max_Min.xlsx\".format(path_list[-1][:-5]),\n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "        # Saving daily average water level timeseries file\n",
    "        equi_davg_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Output\\Daily_Avg\\{}_Daily_Avg.xlsx\".format(path_list[-1][:-5]),\n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "        # Saving fortnightly average water level\n",
    "        fawl_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Output\\Fortnightly_Avg\\{}_Fortnightly_Avg.xlsx\".format(path_list[-1][:-5]),\n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "#         print(path_list[-1][:-5])\n",
    "        \n",
    "    except:\n",
    "        print('!!!!ERROR!!!! ' + path_list[-1][:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ebd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mikeio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from calendar import monthrange\n",
    "\n",
    "\n",
    "# function for creating blank time series at \"specified interval\" \n",
    "# creating a dictinary with first_date & end_date of each month of each year \n",
    "def blank_ts_and_year_dict(dataframe):\n",
    "\n",
    "    df = dataframe\n",
    "\n",
    "    start_end_time_dict = {}\n",
    "\n",
    "    total_time_df = pd.DataFrame()\n",
    "\n",
    "    start_yr = df['Date'].dt.year.unique().min()\n",
    "    end_yr = df['Date'].dt.year.unique().max()\n",
    "\n",
    "\n",
    "    year_list = [y for y in range(start_yr, end_yr+1 , 1)]\n",
    "\n",
    "    for yr in year_list:\n",
    "\n",
    "        year_dict = {}\n",
    "\n",
    "        yr_df = df[df['Date'].dt.strftime('%Y') == str(yr)]\n",
    "\n",
    "        months_list = [m for m in range(1, 12+1 , 1)]\n",
    "\n",
    "\n",
    "        yearly_time_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        for month in months_list:\n",
    "\n",
    "            start_end_time_list = []\n",
    "\n",
    "            end_day = monthrange(yr, month)[1]\n",
    "\n",
    "            start_date = (datetime(year= yr, month= month, day=1, hour=0, minute=0, second =0)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            end_date = (datetime(year= yr, month= month, day= end_day, hour=23, minute=30, second =0)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            start_end_time_list.append(start_date)\n",
    "            start_end_time_list.append(end_date)\n",
    "\n",
    "            monthly_time_list = pd.date_range(start_date, end_date, freq=\"30min\")\n",
    "\n",
    "            monthly_time_df = pd.DataFrame({'Date':monthly_time_list})\n",
    "\n",
    "            yearly_time_df = pd.concat([yearly_time_df,monthly_time_df])\n",
    "\n",
    "            year_dict[str(month)] = start_end_time_list\n",
    "\n",
    "        total_time_df = pd.concat([total_time_df,yearly_time_df])\n",
    "\n",
    "        start_end_time_dict[str(yr)] = year_dict\n",
    "\n",
    "    return total_time_df, start_end_time_dict\n",
    "\n",
    "\n",
    "# Defining a function to extract daily maximum and minimum value and calculating their average\n",
    "def daily_avg_wl_df(timeseries_df, column_name):\n",
    "    \n",
    "    without_duplicate_df = timeseries_df\n",
    "\n",
    "    max_min_column = column_name\n",
    "\n",
    "    # Extracting daily max and min value from timeseries data\n",
    "    # Defining two dataframes to store daily maximum and minimum value\n",
    "    max_df = pd.DataFrame()\n",
    "    min_df = pd.DataFrame()\n",
    "\n",
    "    # looping through all the unique date in the timeseries dataframe to determine daily maximum and minimum value\n",
    "    for day in without_duplicate_df['Date'].dt.date.unique():\n",
    "\n",
    "        # Creating a dataframe by matching the date\n",
    "        day_df = without_duplicate_df[without_duplicate_df['Date'].dt.date == day]\n",
    "\n",
    "        # Finding daily maximum and minimum value for the required cloumn and also extracting associated other column data\n",
    "        max_row_df = day_df.nlargest(1, max_min_column)\n",
    "        min_row_df = day_df.nsmallest(1, max_min_column)\n",
    "\n",
    "        # Updating the maximum and minimum value in the max_df and min_df respectively\n",
    "        max_df = pd.concat([max_df, max_row_df])\n",
    "        min_df = pd.concat([min_df, min_row_df])\n",
    "\n",
    "    # Creating a dataframe by merging maximum and minimum dataframe\n",
    "    daily_max_min_df = pd.concat([max_df, min_df])\n",
    "\n",
    "    # Sorting the dataframe by \"Date\" [Oldest to Newest]\n",
    "    daily_max_min_df.sort_values(by='Date',ascending=True, inplace = False)\n",
    "\n",
    "    # Calculating daily average value from daily maximum and minimum value and reseting the index\n",
    "    davg_df = daily_max_min_df.groupby(by=daily_max_min_df['Date'].dt.date).mean()\n",
    "    davg_df.reset_index(inplace = True)\n",
    "    davg_df['Date'] = pd.to_datetime(davg_df['Date'], format=\"%Y-%m-%d\")\n",
    "    \n",
    "    return daily_max_min_df, davg_df\n",
    "\n",
    "\n",
    "# Function for calculating the average of each column the dataframe except the date column and then transposing it\n",
    "def df_column_avg(df):\n",
    "    \n",
    "    a_df = pd.DataFrame(df.loc[:, df.columns != \"Date\"].mean())\n",
    "    ret_df = a_df.transpose()\n",
    "    \n",
    "    return ret_df\n",
    "\n",
    "\n",
    "\n",
    "# Function for creating segment wise water level average \n",
    "def seg_wl_average(no_of_intervals, time_dic, timeseries_df):\n",
    "\n",
    "    N = no_of_intervals\n",
    "    start_end_time_dict = time_dic\n",
    "    m_df = timeseries_df\n",
    "    \n",
    "    wl_df = pd.DataFrame()\n",
    "    \n",
    "    for yr_key in start_end_time_dict:\n",
    "        for month_key in start_end_time_dict[yr_key]:\n",
    "            first_date = start_end_time_dict[yr_key][month_key][0]\n",
    "            last_date = start_end_time_dict[yr_key][month_key][1]\n",
    "\n",
    "            start_datetime = pd.to_datetime(first_date)\n",
    "            end_datetime = pd.to_datetime(last_date)\n",
    "\n",
    "\n",
    "            dtm_list = []\n",
    "\n",
    "            diff = end_datetime - start_datetime\n",
    "\n",
    "            increment = (diff.round('D') - timedelta(days = diff.round('D').days % N))/ N\n",
    "\n",
    "            for idx in range(1, N+1, 1):\n",
    "\n",
    "                if idx == 0:\n",
    "                    dtm_list.append((start_datetime + idx * increment).strftime(\"%Y/%m/%d\"))\n",
    "\n",
    "                elif 0 < idx < N:\n",
    "                    dtm_list.append((start_datetime + idx * increment - timedelta(days=1)).strftime(\"%Y/%m/%d\"))\n",
    "\n",
    "                else:\n",
    "                    dtm_list.append((end_datetime).strftime(\"%Y/%m/%d\"))\n",
    "                    \n",
    "\n",
    "            for i in range(0,len(dtm_list)):\n",
    "\n",
    "                if i == 0:\n",
    "                    mask = (m_df['Date'] >= start_datetime) & (m_df['Date'] <= dtm_list[i])\n",
    "                    v_df = m_df.loc[mask]\n",
    "\n",
    "\n",
    "                    fdt_df = pd.DataFrame({'Date/Time':[dtm_list[i]]})\n",
    "                    avg_df = df_column_avg(v_df)\n",
    "                    n_df = pd.concat([fdt_df,avg_df], axis=1, join=\"inner\")\n",
    "                    n_df['Remarks'] = i+1\n",
    "\n",
    "                    wl_df = pd.concat([wl_df, n_df])\n",
    "\n",
    "                elif 0 < i < len(dtm_list):\n",
    "                    mask = (m_df['Date'] > dtm_list[i-1]) & (m_df['Date'] <= dtm_list[i])\n",
    "                    v_df = m_df.loc[mask]\n",
    "\n",
    "                    fdt_df = pd.DataFrame({'Date/Time':[dtm_list[i]]})\n",
    "                    avg_df = df_column_avg(v_df)\n",
    "                    n_df = pd.concat([fdt_df,avg_df], axis=1, join=\"inner\")\n",
    "                    n_df['Remarks'] = i+1\n",
    "\n",
    "                    wl_df = pd.concat([wl_df, n_df])\n",
    "\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "    return wl_df\n",
    "\n",
    "for file in glob.glob(r'G:\\MJI\\BWDB_Tidal (104 nos.)\\Tidal (104 nos.)\\Problem\\*.dfs0'):\n",
    "    \n",
    "    try:\n",
    "        path_list = file.split(os.sep)\n",
    "\n",
    "        # Reading dfs0 file\n",
    "        ds = mikeio.read(file)\n",
    "\n",
    "        # Converting dataset to dataframe\n",
    "        df = ds.to_dataframe()\n",
    "\n",
    "        # Creating the date/time column and renaming it\n",
    "        df.reset_index(inplace =True)\n",
    "        df.rename(columns = {'index':'Date'}, inplace = True)\n",
    "        df.sort_values(by='Date',ascending=True, inplace = True)\n",
    "\n",
    "        # Rounding datetime time to nearest 30 minutes\n",
    "        df['Date'] = df.loc[:,'Date'].dt.round(freq='30T')\n",
    "\n",
    "\n",
    "        # Creating a datetime timeseries at 30 minutes interval \n",
    "        total_time_df, start_end_time_dict = blank_ts_and_year_dict(df)\n",
    "        total_time_df.reset_index(inplace = True, drop=True)\n",
    "\n",
    "        # Droping the 'Duplicate rows' and keeping the first value from duplicate rows\n",
    "        without_duplicate_df = df.drop_duplicates(subset=['Date'], keep='first')\n",
    "\n",
    "\n",
    "        # Merging Blank timeseries dataframe and processed dataframe from input timeseries together\n",
    "        ts_df = total_time_df.merge(without_duplicate_df, how=\"outer\", on=\"Date\")\n",
    "        ts_df.sort_values(by='Date',ascending=True, inplace = True)\n",
    "        ts_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        # Extracting the daily maximum and minimum and calculating their average, then returning their average using defined function\n",
    "        daily_max_min_df, davg_df = daily_avg_wl_df(timeseries_df = without_duplicate_df, column_name = 'Modified_Cyclone')\n",
    "\n",
    "        # Defining a dataframe blank daily timeseries dataframe (frequency = 1 day)\n",
    "        daily_ts_df = pd.DataFrame({'Date':ts_df['Date'].dt.date.unique()})\n",
    "        daily_ts_df['Date'] = pd.to_datetime(daily_ts_df['Date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "        # Merging daily blank timeseries dataframe and processed (from input timeseries) daily average water level dataframe together\n",
    "        equi_davg_df = daily_ts_df.merge(davg_df, how=\"outer\", on=\"Date\")\n",
    "\n",
    "        # Total number time segment in a month (example: fortnightly-2, weekly-4 etc.) [User Input]\n",
    "        no_of_intervals = 2   ## Fortnightly\n",
    "\n",
    "        # Applying function to calculate fortnightly average water level\n",
    "        fawl_df = seg_wl_average(no_of_intervals = no_of_intervals, time_dic = start_end_time_dict , timeseries_df = equi_davg_df)\n",
    "\n",
    "\n",
    "        # Saving 30 minutes interval timeseries file\n",
    "        ts_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Tidal (104 nos.)\\Problem\\{}_30min_TS.xlsx\".format(path_list[-1][:-5]), \n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "        # Saving daily maximum and minimum timeseries file\n",
    "        daily_max_min_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Tidal (104 nos.)\\Problem\\{}_Daily_Max_Min.xlsx\".format(path_list[-1][:-5]),\n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "        # Saving daily average water level timeseries file\n",
    "        equi_davg_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Tidal (104 nos.)\\Problem\\{}_Daily_Avg.xlsx\".format(path_list[-1][:-5]),\n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "        # Saving fortnightly average water level\n",
    "        fawl_df.to_excel(r\"G:\\MJI\\BWDB_Tidal (104 nos.)\\Tidal (104 nos.)\\Problem\\{}_Fortnightly_Avg.xlsx\".format(path_list[-1][:-5]),\n",
    "                       float_format=\"%.3f\", index= False)\n",
    "\n",
    "#         print(path_list[-1][:-5])\n",
    "        \n",
    "    except:\n",
    "        print('!!!!ERROR!!!! ' + path_list[-1][:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68178b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
